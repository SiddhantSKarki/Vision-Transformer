{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bae88d5e-cbcd-445a-b6f1-dc0ed68840fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# random_state in C (check vit.c)-> 69\n",
    "# CLS+Patch Embeddings (5 x 4)\n",
    "cls_patch_embeddings = torch.tensor([\n",
    "    [0.7825, 1.0174,   1.6778,   1.2251],\n",
    "    [3.3223, 2.8748, 3.0050, 3.2986],\n",
    "    [3.3452, 2.4302, 3.0276, 2.3968],\n",
    "    [3.0843, 3.1493, 2.6917, 3.3506],\n",
    "    [3.5323, 3.3369, 2.9087, 2.9229]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "135d5494-0085-4299-a553-d34eaba68ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4, 6])\n",
      "tensor([[[[0.2771, 0.9177, 0.6750, 0.4321, 0.9526, 0.5549],\n",
      "          [0.6051, 0.9398, 0.2410, 0.8902, 0.0560, 0.6765],\n",
      "          [0.3281, 0.9908, 0.2155, 0.6071, 0.4933, 0.1080],\n",
      "          [0.5215, 0.7952, 0.1658, 0.4366, 0.8078, 0.2068]],\n",
      "\n",
      "         [[0.2136, 0.3869, 0.1732, 0.7026, 0.3515, 0.9694],\n",
      "          [0.2413, 0.6287, 0.8870, 0.9163, 0.0608, 0.8397],\n",
      "          [0.4712, 0.6659, 0.7795, 0.7121, 0.5561, 0.8354],\n",
      "          [0.3886, 0.8843, 0.8263, 0.6041, 0.4914, 0.3195]]],\n",
      "\n",
      "\n",
      "        [[[0.7120, 0.0129, 0.1147, 0.8778, 0.4495, 0.9225],\n",
      "          [0.0846, 0.6631, 0.3095, 0.2578, 0.3657, 0.6610],\n",
      "          [0.2271, 0.6070, 0.2896, 0.1141, 0.5233, 0.3505],\n",
      "          [0.9538, 0.9945, 0.0164, 0.7332, 0.7066, 0.5725]],\n",
      "\n",
      "         [[0.5687, 0.0952, 0.4567, 0.3949, 0.6993, 0.9481],\n",
      "          [0.7145, 0.4113, 0.9610, 0.8292, 0.2892, 0.4106],\n",
      "          [0.7517, 0.3738, 0.0736, 0.0612, 0.6315, 0.4393],\n",
      "          [0.7222, 0.8586, 0.0463, 0.0118, 0.9728, 0.5696]]]])\n"
     ]
    }
   ],
   "source": [
    "# Given matrix as a flat list\n",
    "qkv_multihead_blocks = [\n",
    "    [0.2771, 0.9177, 0.6750, 0.4321, 0.9526, 0.5549],\n",
    "    [0.6051, 0.9398, 0.2410, 0.8902, 0.0560, 0.6765],\n",
    "    [0.3281, 0.9908, 0.2155, 0.6071, 0.4933, 0.1080],\n",
    "    [0.5215, 0.7952, 0.1658, 0.4366, 0.8078, 0.2068],\n",
    "    [0.2136, 0.3869, 0.1732, 0.7026, 0.3515, 0.9694],\n",
    "    [0.2413, 0.6287, 0.8870, 0.9163, 0.0608, 0.8397],\n",
    "    [0.4712, 0.6659, 0.7795, 0.7121, 0.5561, 0.8354],\n",
    "    [0.3886, 0.8843, 0.8263, 0.6041, 0.4914, 0.3195],\n",
    "    [0.7120, 0.0129, 0.1147, 0.8778, 0.4495, 0.9225],\n",
    "    [0.0846, 0.6631, 0.3095, 0.2578, 0.3657, 0.6610],\n",
    "    [0.2271, 0.6070, 0.2896, 0.1141, 0.5233, 0.3505],\n",
    "    [0.9538, 0.9945, 0.0164, 0.7332, 0.7066, 0.5725],\n",
    "    [0.5687, 0.0952, 0.4567, 0.3949, 0.6993, 0.9481],\n",
    "    [0.7145, 0.4113, 0.9610, 0.8292, 0.2892, 0.4106],\n",
    "    [0.7517, 0.3738, 0.0736, 0.0612, 0.6315, 0.4393],\n",
    "    [0.7222, 0.8586, 0.0463, 0.0118, 0.9728, 0.5696]\n",
    "]\n",
    "\n",
    "# Convert to tensor\n",
    "tensor = torch.tensor(qkv_multihead_blocks)\n",
    "# Reshape into (Blocks=2, Heads=2, Head_Size=4, QKV=6)\n",
    "tensor = tensor.view(2, 2, 4, 6)\n",
    "print(tensor.shape)  # Should output torch.Size([2, 2, 4, 6])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "962588ef-ab5d-4d9b-abf7-927d54ce18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = 1\n",
    "head = 0\n",
    "Q,K,V = tensor[:,:,:,:2], tensor[:,:,:,2:4], tensor[:,:,:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e8d4e9cb-771f-49b8-88c7-65eb582634b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_out = cls_patch_embeddings@Q\n",
    "K_out = cls_patch_embeddings@K\n",
    "V_out = cls_patch_embeddings@V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b355c521-f5fd-4c2a-b48a-4b92c5f5ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(mat, name):\n",
    "    print(name, mat.shape)\n",
    "    print(mat, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7a87d890-00e3-428c-a6f6-3087a46df626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Result:  torch.Size([2, 2, 5, 2])\n",
      "tensor([[[[ 2.0218,  4.3108],\n",
      "          [ 5.3663, 11.3510],\n",
      "          [ 4.6408, 10.2595],\n",
      "          [ 5.3908, 11.1215],\n",
      "          [ 5.4766, 11.5838]],\n",
      "\n",
      "         [[ 1.6793,  3.1430],\n",
      "          [ 4.1011,  8.0108],\n",
      "          [ 3.6589,  6.9577],\n",
      "          [ 3.9891,  7.9286],\n",
      "          [ 4.0661,  7.9862]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1927,  2.9215],\n",
      "          [ 6.4373,  7.0536],\n",
      "          [ 5.5610,  5.8760],\n",
      "          [ 6.2695,  7.0941],\n",
      "          [ 6.2457,  6.9307]],\n",
      "\n",
      "         [[ 3.3179,  2.1720],\n",
      "          [ 8.5845,  5.4541],\n",
      "          [ 7.6456,  4.5076],\n",
      "          [ 8.4474,  5.4719],\n",
      "          [ 8.6904,  5.3056]]]]) \n",
      "\n",
      "\n",
      "Key Result:  torch.Size([2, 2, 5, 2])\n",
      "tensor([[[[1.3381, 2.7973],\n",
      "          [4.1299, 7.2592],\n",
      "          [3.8935, 6.4933],\n",
      "          [3.9765, 7.2332],\n",
      "          [4.2999, 7.5388]],\n",
      "\n",
      "         [[3.3581, 3.4169],\n",
      "          [8.1934, 9.1010],\n",
      "          [7.0755, 8.1810],\n",
      "          [8.1944, 8.9936],\n",
      "          [8.2541, 9.3764]]],\n",
      "\n",
      "\n",
      "        [[[0.9106, 2.0388],\n",
      "          [2.1952, 6.4188],\n",
      "          [2.0519, 5.6657],\n",
      "          [2.1629, 6.2831],\n",
      "          [2.3282, 6.4359]],\n",
      "\n",
      "         [[1.5153, 1.2698],\n",
      "          [4.6539, 3.9186],\n",
      "          [4.1970, 3.5497],\n",
      "          [4.7883, 4.0337],\n",
      "          [5.1694, 4.3744]]]]) \n",
      "\n",
      "\n",
      "Value Result:  torch.Size([2, 2, 5, 2])\n",
      "tensor([[[[2.6197, 1.5570],\n",
      "          [7.4728, 4.7950],\n",
      "          [6.7524, 4.3229],\n",
      "          [7.1489, 4.8256],\n",
      "          [7.3477, 5.1361]],\n",
      "\n",
      "         [[1.8719, 3.4059],\n",
      "          [4.6346, 9.1989],\n",
      "          [4.1850, 8.5785],\n",
      "          [4.4189, 8.9536],\n",
      "          [4.4983, 9.5900]]],\n",
      "\n",
      "\n",
      "        [[[2.4674, 2.6838],\n",
      "          [6.4480, 7.9068],\n",
      "          [5.6703, 7.1257],\n",
      "          [6.3142, 7.7886],\n",
      "          [6.3955, 8.1571]],\n",
      "\n",
      "         [[3.0927, 2.5945],\n",
      "          [8.2612, 7.5292],\n",
      "          [7.2856, 6.8647],\n",
      "          [8.0269, 7.3083],\n",
      "          [8.1154, 7.6618]]]]) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_info(Q_out, \"Query Result: \")\n",
    "print_info(K_out, \"Key Result: \")\n",
    "print_info(V_out, \"Value Result: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d08ae769-0a58-4d37-b495-0eb0b616012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def simplified_attention(Q, K, V):\n",
    "    d_k = Q.shape[-1]\n",
    "    attn_scores = torch.matmul(Q, K.transpose(-2, -1)) \n",
    "    attn_scores = attn_scores / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "    attn_weights = torch.softmax(attn_scores, dim=-1) \n",
    "    attn_output = torch.matmul(attn_weights, V)\n",
    "\n",
    "    return attn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec56cbd-940f-455b-b37f-0f30cea48ce1",
   "metadata": {},
   "source": [
    "# Outputs from all blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cbfd5534-5b21-4083-9851-5e498d7e1cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[7.3345, 5.0054],\n",
       "          [7.3495, 5.1113],\n",
       "          [7.3494, 5.1024],\n",
       "          [7.3495, 5.1103],\n",
       "          [7.3495, 5.1127]],\n",
       "\n",
       "         [[4.5149, 9.3462],\n",
       "          [4.5112, 9.4877],\n",
       "          [4.5129, 9.4647],\n",
       "          [4.5114, 9.4858],\n",
       "          [4.5112, 9.4871]]],\n",
       "\n",
       "\n",
       "        [[[6.3548, 7.9389],\n",
       "          [6.3978, 8.0339],\n",
       "          [6.3936, 8.0190],\n",
       "          [6.3979, 8.0328],\n",
       "          [6.3975, 8.0317]],\n",
       "\n",
       "         [[8.0987, 7.5714],\n",
       "          [8.1141, 7.6516],\n",
       "          [8.1135, 7.6453],\n",
       "          [8.1141, 7.6513],\n",
       "          [8.1141, 7.6516]]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_attention(Q_out, K_out.T, V_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
